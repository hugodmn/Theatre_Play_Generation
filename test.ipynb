{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from tqdm import tqdm \n",
    "import pandas as pd \n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': '---\\nname: Dreadnought\\ntype: AV\\nspeed: 15cm\\narmour: 3+\\ncc: 4+\\nff: 4+\\nspecial_rules:\\n  - walker\\nnotes:\\n  |\\n    Armed with either a Missile Launcher and Twin Lascannon, or an Assault Cannon and Power Fist.\\nweapons:\\n  -\\n    id: missile-launcher\\n    multiplier: 0–1\\n  -\\n    id: twin-lascannon\\n    multiplier: 0–1\\n  -\\n    id: assault-cannon\\n    multiplier: 0–1\\n  -\\n    id: power-fist\\n    multiplier: 0–1\\n---', 'repo_name': 'dsusco/tp.net-armageddon.org', 'path': '_site/_units/dreadnought.md', 'language': 'Markdown', 'license': 'isc', 'size': 409}\n"
     ]
    }
   ],
   "source": [
    "# ds = load_dataset(\"codeparrot/github-code\", streaming=True, split=\"train\", languages = [\"Markdown\"], keep_in_memory=False)\n",
    "\n",
    "# print(next(iter(ds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/shakespeare-plays/Shakespeare_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_corpus = []\n",
    "\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    processed_corpus.append(row['PlayerLine'].lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['act i', 'scene i. london. the palace.', 'enter king henry, lord john of lancaster, the earl of westmoreland, sir walter blunt, and others', 'so shaken as we are, so wan with care,', 'find we a time for frighted peace to pant,', 'and breathe short-winded accents of new broils', 'to be commenced in strands afar remote.', 'no more the thirsty entrance of this soil', \"shall daub her lips with her own children's blood,\", 'nor more shall trenching war channel her fields,']\n"
     ]
    }
   ],
   "source": [
    "print(processed_corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, block_size : int, split : str ,  to_lower : bool = True):\n",
    "        self.data = pd.read_csv('datasets/shakespeare-plays/Shakespeare_data.csv')\n",
    "        self.processed_corpus = []\n",
    "        self.block_size = block_size\n",
    "        \n",
    "\n",
    "        for i, row in self.data.iterrows():\n",
    "            if to_lower:\n",
    "                self.processed_corpus.append(row['PlayerLine'].lower())\n",
    "            else : \n",
    "                self.processed_corpus.append(row['PlayerLine'])\n",
    "        \n",
    "        if split == 'train':\n",
    "            self.processed_corpus = self.processed_corpus[:int(0.9*len(self.processed_corpus))]\n",
    "        elif split == 'test':\n",
    "            self.processed_corpus = self.processed_corpus[int(0.9*len(self.processed_corpus)):]\n",
    "\n",
    "        #Merge all the lines into one big string\n",
    "        self.processed_corpus = '\\n'.join(self.processed_corpus)\n",
    "     \n",
    "        vocab_chars = set()\n",
    "        for line in self.processed_corpus:\n",
    "            for char in line:\n",
    "                if char not in vocab_chars:\n",
    "                    vocab_chars.add(char)\n",
    "        \n",
    "        self.vocab_size = len(sorted(vocab_chars))\n",
    "        self.token_embedding_table = nn.Embedding(self.vocab_size, self.vocab_size)\n",
    "        self.stoi = {char: i for i, char in enumerate(sorted(vocab_chars))}\n",
    "        self.itos = {i: char for i, char in enumerate(sorted(vocab_chars))}\n",
    "        # self.encode = lambda x: [stoi[char] for char in x]\n",
    "        # self.decode = lambda x: [itos[i] for i in x] \n",
    "\n",
    "    def decode(self, x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            x = x.tolist()\n",
    "        return [self.itos[i] for i in x]\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return [int(self.stoi[char]) for char in x]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(self.encode(self.processed_corpus[idx : idx + self.block_size + 3]))\n",
    "        context = self.processed_corpus[idx : idx + self.block_size + 1]\n",
    "        prediction = self.processed_corpus[idx + self.block_size + 1]\n",
    "        encoded_context = self.encode(context)\n",
    "        encoded_prediction = self.encode(prediction)\n",
    "\n",
    "        encoded_prediction = torch.Tensor(encoded_prediction).type(torch.int32)\n",
    "  \n",
    "        encoded_prediction = self.token_embedding_table(encoded_prediction).squeeze(0)\n",
    "   \n",
    "        encoded_context = torch.Tensor(encoded_context).type(torch.int32)\n",
    "        print(encoded_context.shape)\n",
    "        \n",
    "        return encoded_context, encoded_prediction\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.processed_corpus) - self.block_size - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ShakespeareDataset(block_size = 32, split = 'train')\n",
    "test_dataset = ShakespeareDataset(block_size = 32, split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([44.,  2., 33.,  1., 43., 27., 29., 38., 29.,  2., 33., 10.,  2., 36.,\n",
       "         39., 38., 28., 39., 38., 10.,  2., 44., 32., 29.,  2., 40., 25., 36.,\n",
       "         25., 27., 29., 10.,  1.]),\n",
       " tensor([29.]))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2., 33.,  1., 43., 27., 29., 38., 29.,  2., 33., 10.,  2., 36., 39.,\n",
       "         38., 28., 39., 38., 10.,  2., 44., 32., 29.,  2., 40., 25., 36., 25.,\n",
       "         27., 29., 10.,  1., 29.]),\n",
       " tensor([38.]))"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['act i',\n",
       " 'scene i. london. the palace.',\n",
       " 'enter king henry, lord john of lancaster, the earl of westmoreland, sir walter blunt, and others',\n",
       " 'so shaken as we are, so wan with care,',\n",
       " 'find we a time for frighted peace to pant,',\n",
       " 'and breathe short-winded accents of new broils',\n",
       " 'to be commenced in strands afar remote.',\n",
       " 'no more the thirsty entrance of this soil',\n",
       " \"shall daub her lips with her own children's blood,\",\n",
       " 'nor more shall trenching war channel her fields,',\n",
       " 'nor bruise her flowerets with the armed hoofs',\n",
       " 'of hostile paces: those opposed eyes,',\n",
       " 'which, like the meteors of a troubled heaven,',\n",
       " 'all of one nature, of one substance bred,',\n",
       " 'did lately meet in the intestine shock',\n",
       " 'and furious close of civil butchery',\n",
       " 'shall now, in mutual well-beseeming ranks,',\n",
       " 'march all one way and be no more opposed',\n",
       " 'against acquaintance, kindred and allies:']"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_corpus[0:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "wei = torch.randn(32,33,33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 33])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tril(torch.ones(33,33))==0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wei.masked_fill((torch.tril(torch.ones(33,33)))==0, float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAttentionHead(nn.Module):\n",
    "    def __init__(self, emb_size : int, head_size : int):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.head_size = head_size\n",
    "        #self.block_size = block_size\n",
    "        self.q_linear = nn.Linear(self.emb_size, self.head_size)\n",
    "        self.v_linear = nn.Linear(self.emb_size, self.head_size)\n",
    "        self.k_linear = nn.Linear(self.emb_size, self.head_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.k_linear(x)\n",
    "        q = self.q_linear(x) # B, T, C\n",
    "\n",
    "        wei = q @ k.transpose(-2,-1) / self.head_size # B, T, T\n",
    "\n",
    "        wei = wei.masked_fill((torch.tril(torch.ones(T,T))==0).to(x.device), float('-inf')).to(x.device)\n",
    "        wei = torch.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        v = self.v_linear(x)\n",
    "        out = wei @ v # B, T, C\n",
    "\n",
    "\n",
    "        return out.to(x.device)\n",
    "    \n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, head_nb : int, emb_size : int):\n",
    "        super().__init__()\n",
    "        self.head_nb = head_nb\n",
    "        self.emb_size = emb_size\n",
    "        self.heads = nn.ModuleList([SingleAttentionHead(self.emb_size, self.emb_size//self.head_nb) for _ in range(head_nb)])\n",
    "        self.proj = nn.Linear(emb_size, emb_size)\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, emb_size : int, head_nb : int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.MHA = MultiHeadAttention(head_nb, emb_size)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "                nn.Linear(emb_size, 4*emb_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4*emb_size, emb_size),\n",
    "                nn.Dropout(0.0)\n",
    "        )\n",
    "          \n",
    "        self.ln = nn.LayerNorm(emb_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.ln(x)\n",
    "        out = self.MHA(x)\n",
    "        out = out + x \n",
    "        out = self.ln(x)\n",
    "        out = self.feed_forward(out)\n",
    "        out = out + x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM(nn.Module):\n",
    "    def __init__(self, vocab_size : int, emb_size : int, head_nb : int, block_nb : int, block_size : int):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.head_nb = head_nb\n",
    "        self.block_nb = block_nb\n",
    "        self.block_size = block_size\n",
    "\n",
    "        self.tok_emb = nn.Embedding(vocab_size, emb_size)\n",
    "        self.pos_emb = nn.Embedding(self.block_size, emb_size)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(self.emb_size, self.head_nb) for _ in range(self.block_nb)])\n",
    "        \n",
    "        self.ln = nn.LayerNorm(self.emb_size)\n",
    "        self.lm_head = nn.Linear(self.emb_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T = x.shape\n",
    "        \n",
    "        tok_emb =  self.tok_emb(x)\n",
    "        pos_emb = self.pos_emb(torch.arange(T, device = x.device))\n",
    "        \n",
    "        out = tok_emb + pos_emb\n",
    "        for block in self.blocks:\n",
    "            out = block(out)\n",
    "        #out = self.blocks(out)\n",
    "        logits = self.lm_head(out)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2587352704.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[372], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    total_acc += (logits.argmax(-1) == predi:,1:]).sum().item()\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def train(model, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    total_acc = 0\n",
    "    with tqdm(range(len(train_loader))) as pbar :\n",
    "        for idx, (context,predi) in enumerate(train_loader):\n",
    "            context, predi = context.to(device), predi.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            print(context)\n",
    "            logits = model(context)\n",
    "            print(logits.shape, predi.shape)\n",
    "            loss = nn.CrossEntropyLoss()(logits, predi)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 100 == 0:\n",
    "                print(loss.item())\n",
    "            total_acc += (logits.argmax(-1) == predi:,1:]).sum().item()\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f'[TRAIN] Accuracy : {total_acc/len(train_dataset)} Loss : {loss.item()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_acc = 0 \n",
    "        with tqdm(range(len(test_loader))) as pbar :\n",
    "            for idx, (context, predi) in enumerate(test_loader):\n",
    "                context, predi = context.to(device), predi.to(device)\n",
    "                print(context)\n",
    "                logits = model(context)\n",
    "                loss = nn.CrossEntropyLoss()(logits[:,:-1].reshape(-1, vocab_size), x[:,1:].reshape(-1))\n",
    "                #accuracy\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                acc = (pred == predi).float().mean()\n",
    "                total_acc += acc.item()\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    print(loss.item())\n",
    "                pbar.update(1)\n",
    "        print(f'[TEST] Accuracy : {total_acc/len(test_dataset)} Loss : {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 15333, 1049, 1005, 10439, 5349, 2571, 2888, 999, 5292, 3270, 8840, 2140, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "[CLS] je m'appellle henry! haha lol [SEP]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "test = \"Je m'appellle Henry ! haha lol\"\n",
    "test_encoded = tokenizer(test)\n",
    "print(test_encoded)\n",
    "text_decoded = tokenizer.decode(test_encoded['input_ids'])\n",
    "print(text_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "\n",
    "\n",
    "block_size = 32 # -> context length \n",
    "vocab_size = train_dataset.vocab_size\n",
    "emb_size = 512\n",
    "head_nb = 8\n",
    "block_nb = 6\n",
    "\n",
    "model = LLM(vocab_size, emb_size, head_nb, block_nb, block_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/123045 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "torch.Size([33])\n",
      "tensor([[33, 28, 43,  ..., 28, 42, 29],\n",
      "        [45, 42,  2,  ...,  1,  5, 44],\n",
      "        [43,  2, 45,  ...,  2, 43, 33],\n",
      "        ...,\n",
      "        [37,  2, 32,  ..., 40, 42, 25],\n",
      "        [44, 33, 39,  ..., 29, 25, 44],\n",
      "        [43, 32, 25,  ..., 25, 43, 44]], device='mps:0', dtype=torch.int32)\n",
      "torch.Size([32, 33])\n",
      "torch.Size([32, 33, 51]) torch.Size([32, 51])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(f'EPOCH {i+1}')\n",
    "    train(model, optimizer, train_loader, device)\n",
    "    test(test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123045"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
